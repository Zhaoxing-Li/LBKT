{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f99f5e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import psutil\n",
    "import joblib\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "39db5e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SAMPLES = 320000\n",
    "\n",
    "MAX_SEQ = 100\n",
    "# MAX_SEQ = 128\n",
    "MIN_SAMPLES = 5\n",
    "EMBED_DIM = 128\n",
    "DROPOUT_RATE = 0.2\n",
    "LEARNING_RATE = 1e-3\n",
    "# LEARNING_RATE = 1e-5\n",
    "MAX_LEARNING_RATE = 2e-3\n",
    "# EPOCHS = 30\n",
    "EPOCHS = 10\n",
    "# TRAIN_BATCH_SIZE = 2048\n",
    "TRAIN_BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80833b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number skills 13523\n",
      "TRAIN_SAMPLES 314924\n",
      "train_group \n",
      " user_id\n",
      "115     ([5692, 5716, 128, 7860, 7922, 156, 51, 50, 78...\n",
      "124     ([7900, 7876, 175, 1278, 2065, 2063, 2064, 336...\n",
      "2746    ([5273, 758, 5976, 236, 404, 382, 405, 873, 53...\n",
      "5382    ([5000, 3944, 217, 5844, 5965, 4990, 5235, 605...\n",
      "8623    ([3915, 4750, 6456, 3968, 6104, 5738, 6435, 54...\n",
      "dtype: object\n",
      "valid_group \n",
      " user_id\n",
      "1720820513    ([3849, 1320, 5285, 8918, 3644, 6111, 8397, 94...\n",
      "1720823127    ([7900, 7876, 175, 1278, 2064, 2065, 2063, 336...\n",
      "1720823509    ([128, 7860, 7922, 156, 51, 50, 7896, 7863, 15...\n",
      "1720827508    ([7900, 7876, 175, 1278, 2065, 2063, 2064, 336...\n",
      "1720827841    ([7900, 7876, 175, 1278, 2065, 2063, 2064, 336...\n",
      "dtype: object\n",
      "314924 78732\n",
      "CPU times: user 1min 2s, sys: 5.45 s, total: 1min 7s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dtypes = {'timestamp': 'int64', 'user_id': 'int32' ,'content_id': 'int16','content_type_id': 'int8','answered_correctly':'int8'}\n",
    "# train_df = pd.read_feather('../input/riiid-cross-validation-dataset/train.feather')[[\n",
    "#     'timestamp', 'user_id', 'content_id', 'content_type_id', 'answered_correctly'\n",
    "# ]]\n",
    "train_df = pd.read_csv('./input/riiid-test-answer-prediction/train.csv')[['timestamp', 'user_id', 'content_id', 'content_type_id', 'answered_correctly']]\n",
    "for col, dtype in dtypes.items():\n",
    "    train_df[col] = train_df[col].astype(dtype)\n",
    "    \n",
    "    \n",
    "#train_df have only rows with False in content_type_id (0 if the event was a question being posed to the user)\n",
    "train_df = train_df[train_df.content_type_id == False]  \n",
    "\n",
    "train_df = train_df.sort_values(['timestamp'], ascending=True)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "skills = train_df[\"content_id\"].unique()\n",
    "# joblib.dump(skills, \"skills.pkl.zip\")\n",
    "n_skill = len(skills)  # (unique content IDs)\n",
    "print(\"number skills\", n_skill)\n",
    "\n",
    "group = train_df[['user_id', 'content_id', 'answered_correctly', 'timestamp']].groupby('user_id').apply(lambda r: (\n",
    "            r['content_id'].values,\n",
    "            r['answered_correctly'].values,\n",
    "            r['timestamp'].values))\n",
    "\n",
    "# joblib.dump(group, \"group.pkl.zip\")\n",
    "del train_df\n",
    "gc.collect()\n",
    "# group\n",
    "\n",
    "# The training data is sorted by timestamp and split into two sets using an 80/20 split\n",
    "TRAIN_SAMPLES = int(len(group.index)*0.8)\n",
    "print('TRAIN_SAMPLES',TRAIN_SAMPLES)\n",
    "\n",
    "\n",
    "# The method then creates a dictionary of samples, where each key is a user ID and the corresponding value is a tuple containing the user's content IDs and answered correctly values.\n",
    "train_indexes = list(group.index)[:TRAIN_SAMPLES]\n",
    "valid_indexes = list(group.index)[TRAIN_SAMPLES:]\n",
    "train_group = group[group.index.isin(train_indexes)]\n",
    "valid_group = group[group.index.isin(valid_indexes)]\n",
    "print('train_group \\n', train_group[:5] )\n",
    "print('valid_group \\n', valid_group[:5] )\n",
    "\n",
    "del group, train_indexes, valid_indexes\n",
    "print(len(train_group), len(valid_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11bae6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_group[115][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6aa38c",
   "metadata": {},
   "source": [
    "### The BERTDataset class returns three values for each sample in the dataset:\n",
    "\n",
    "- `x`: the input data for the BERT model, which consists of the content IDs for each sample shifted by one and the answered correctly values added to the content IDs\n",
    "- `target_id`: the target IDs for each sample, which consist of the content IDs shifted by one\n",
    "- `label`: the labels for each sample, which consist of the answered correctly values shifted by one\n",
    "\n",
    "These values are used as input to the BERT model and are used to calculate the model's performance during training and evaluation. The `x` and `target_id` arrays are used as input to the BERT model, while the `label` array is used to calculate the model's loss and accuracy.\n",
    "\n",
    "The __init__ method iterates over the users in the `group` object and retrieves the questions and answers for each user. If a user has answered fewer than `min_samples` questions, their questions and answers are not included in the `samples` dictionary. If a user has answered more than `max_seq` questions, their questions and answers are split into multiple sequences of length `max_seq` and each sequence is added to the `samples` dictionary using a unique key that includes the user's ID and the sequence number. For example, if the user's ID is `123` and they have answered 150 questions, their questions and answers will be split into two sequences with lengths 128 and 22, and the keys `123_0` and `123_1` will be added to the samples dictionary with the values of the first and second sequence, respectively.\n",
    "\n",
    "### decay rate parameter `k`:\n",
    "- The value of the decay rate parameter k will depend on the time scale of the data and the desired forgetting rate. In general, a larger value of k will result in faster forgetting, while a smaller value will result in slower forgetting.\n",
    "- To choose a suitable value for k, you will need to consider the range of the timestamps and the desired forgetting rate. For example, if you want the decay factor to decrease by half over a period of one hour (3600 seconds), you can set k = ln(2)/3600 so that the decay function f(t) = e^(-kt) satisfies f(3600) = 1/2\n",
    "- It is difficult to recommend a specific value for k without knowing more about the data and the desired forgetting rate. You may need to experiment with different values of k to find the one that works best for your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad5f96f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, group, n_skill, min_samples=1, max_seq=128):\n",
    "        super(BERTDataset, self).__init__()\n",
    "        self.max_seq = max_seq\n",
    "        self.n_skill = n_skill\n",
    "        self.samples = {}\n",
    "        \n",
    "        self.user_ids = []\n",
    "        for user_id in group.index:\n",
    "            q, qa, t = group[user_id]  # q:content_id(questions); qa:answered_correctly(user's question answer)\n",
    "            if len(q) < min_samples:  # If a user has answered fewer than min_samples questions, their questions and answers are not included in the 'samples' dictionary\n",
    "                continue \n",
    "            \n",
    "            # Main Contribution\n",
    "            if len(q) > self.max_seq:\n",
    "                total_questions = len(q)\n",
    "                initial = total_questions % self.max_seq\n",
    "                if initial >= min_samples:\n",
    "                    self.user_ids.append(f\"{user_id}_0\")\n",
    "                    self.samples[f\"{user_id}_0\"] = (q[:initial], qa[:initial], t[:initial])\n",
    "                for seq in range(total_questions // self.max_seq):\n",
    "                    self.user_ids.append(f\"{user_id}_{seq+1}\")\n",
    "                    start = initial + seq * self.max_seq\n",
    "                    end = start + self.max_seq\n",
    "                    self.samples[f\"{user_id}_{seq+1}\"] = (q[start:end], qa[start:end], t[start:end])\n",
    "            else:\n",
    "                user_id = str(user_id)\n",
    "                self.user_ids.append(user_id)\n",
    "                self.samples[user_id] = (q, qa, t)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        user_id = self.user_ids[index]\n",
    "        q_, qa_, t_ = self.samples[user_id]\n",
    "        seq_len = len(q_)\n",
    "\n",
    "        q = np.zeros(self.max_seq, dtype=int)\n",
    "        qa = np.zeros(self.max_seq, dtype=int)\n",
    "        t = np.zeros(self.max_seq, dtype=int)\n",
    "        \n",
    "        if seq_len == self.max_seq:\n",
    "            q[:] = q_\n",
    "            qa[:] = qa_\n",
    "            t[:] = t_\n",
    "        else:\n",
    "            q[-seq_len:] = q_\n",
    "            qa[-seq_len:] = qa_\n",
    "            t[-seq_len:] = t_\n",
    "        \n",
    "        # 'x' also has a length of max_seq-1\n",
    "        target_id = q[1:]  \n",
    "        label = qa[1:]\n",
    "        \n",
    "        \n",
    "        x = np.zeros(self.max_seq-1, dtype=int)\n",
    "        x = q[:-1].copy()\n",
    "        x += (qa[:-1] == 1) * self.n_skill  # the model needs to be able to distinguish between the question IDs and the correct answers in order to make predictions\n",
    "        \n",
    "        # To predict the next response from student, we shouldn't how long a student take for the next question\n",
    "#         times = np.array(list(map(round, t[:-1]/1000)))  # (in seconds) round each number to the nearest integer.\n",
    "        times = np.array(t[:-1])\n",
    "        \n",
    "        \n",
    "#         # decay factor to decrease by half over a period of one hour (3600 seconds)\n",
    "#         k = np.log(2) / 3600\n",
    "#         elapsed_time = t[:-1]/1000  # Elapsed time in seconds\n",
    "#         x = x * np.exp(-k*elapsed_time)  # Update x using the decay factor \n",
    "        \n",
    "        return x, target_id, times, label \n",
    "    \n",
    "    \n",
    "train_dataset = BERTDataset(train_group, n_skill, min_samples=MIN_SAMPLES, max_seq=MAX_SEQ)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "valid_dataset = BERTDataset(valid_group, n_skill, max_seq=MAX_SEQ)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=False, num_workers=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b2eb87",
   "metadata": {},
   "source": [
    "## Define model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0755b2d8",
   "metadata": {},
   "source": [
    "\n",
    "- the `d_model` parameter specifies the size of the hidden states used by the model. This is also known as the \"model size\" or the \"embedding size\" of the model.\n",
    "- The `d_model` parameter is used as a scaling factor when computing the dot product between the query and key vectors in the Attention mechanism. It is also used to specify the size of the input and output vectors for the linear layers in the MultiHeadedAttention class, as well as the size of the input and output vectors for the LayerNorm and SublayerConnection classes. In general, a larger d_model value will result in a more expressive BERT model, but will also increase the computational complexity and memory usage of the model.\n",
    "\n",
    "\n",
    "\n",
    "### Sublayer Connection:\n",
    "- ### residual connection:\n",
    "    - A residual connection is a type of connection in a neural network that allows information to bypass one or more layers of the network. This allows the network to learn to perform tasks more efficiently by allowing the information to flow more directly from the input to the output layers. Residual connections can help improve the performance of the network, particularly on tasks that require the network to process long sequences of data. They are often used in deep learning networks, where they can help prevent the vanishing gradient problem, allowing the network to learn more effectively.\n",
    "    \n",
    "- ### LayerNorm:\n",
    "    - the `eps` parameter specifies a small value used to stabilize the division operation in the layer normalization computation. This is necessary because division by zero is undefined, and division by a very small value can lead to numerical instability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "ca561c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Compute 'Scaled Dot Product Attention' mechanism used by BERT\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, query, key, value, mask=None, dropout=None):\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "                 / math.sqrt(query.size(-1))\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        p_attn = F.softmax(scores, dim=-1)\n",
    "\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    "\n",
    "        return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "\n",
    "# import torch.nn as nn\n",
    "# from .single import Attention\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Take in model size and number of heads.\n",
    "    This class extends the Attention class to support multiple \"heads\" for improved performance\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % h == 0\n",
    "\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "\n",
    "        self.linear_layers = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(3)])\n",
    "        self.output_linear = nn.Linear(d_model, d_model)\n",
    "        self.attention = Attention()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = [l(x).view(batch_size, -1, self.h, self.d_k).transpose(1, 2)\n",
    "                             for l, x in zip(self.linear_layers, (query, key, value))]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, attn = self.attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.h * self.d_k)\n",
    "\n",
    "        return self.output_linear(x)\n",
    "\n",
    "    \n",
    "# implements layer normalization for BERT\n",
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "    \n",
    "# implements the residual connections and layer normalization used by BERT to improve training\n",
    "# from .layer_norm import LayerNorm    \n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "    \n",
    "\n",
    "# activation function used by BERT\n",
    "class GELU(nn.Module):\n",
    "    \"\"\"\n",
    "    Paper Section 3.4, last paragraph notice that BERT used the GELU instead of RELU\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "# from .gelu import GELU\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(self.activation(self.w_1(x))))\n",
    "    \n",
    "    \n",
    "\n",
    "# from .attention import MultiHeadedAttention\n",
    "# from .utils import SublayerConnection, PositionwiseFeedForward\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional Encoder = Transformer (self-attention)\n",
    "    Transformer = MultiHead_Attention + Feed_Forward with sublayer connection\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden, attn_heads, feed_forward_hidden, dropout):\n",
    "        \"\"\"\n",
    "        :param hidden: hidden size of transformer\n",
    "        :param attn_heads: head sizes of multi-head attention\n",
    "        :param feed_forward_hidden: feed_forward_hidden, usually 4*hidden_size\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadedAttention(h=attn_heads, d_model=hidden)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model=hidden, d_ff=feed_forward_hidden, dropout=dropout)\n",
    "        self.input_sublayer = SublayerConnection(size=hidden, dropout=dropout)\n",
    "        self.output_sublayer = SublayerConnection(size=hidden, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.input_sublayer(x, lambda _x: self.attention.forward(_x, _x, _x, mask=mask))\n",
    "        x = self.output_sublayer(x, self.feed_forward)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "# Copy from https://github.com/codertimo/BERT-pytorch\n",
    "class BERT(nn.Module):\n",
    "    \"\"\"\n",
    "    BERT model : Bidirectional Encoder Representations from Transformers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, hidden=128, n_layers=12, attn_heads=12, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param vocab_size: vocab_size of total words\n",
    "        :param hidden: BERT model hidden size\n",
    "        :param n_layers: numbers of Transformer blocks(layers)\n",
    "        :param attn_heads: number of attention heads\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.hidden = hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.attn_heads = attn_heads\n",
    "        \n",
    "        # paper noted they used 4*hidden_size for ff_network_hidden_size\n",
    "        self.feed_forward_hidden = hidden * 4\n",
    "\n",
    "        # embedding for BERT, sum of positional, segment, token embeddings\n",
    "        self.embedding = BERTEmbedding(vocab_size=vocab_size, embed_size=hidden)\n",
    "#         self.embedding = BERTEmbedding(vocab_size=2*vocab_size+1, embed_size=hidden)\n",
    "\n",
    "        # multi-layers transformer blocks, deep network\n",
    "        self.transformer_blocks = nn.ModuleList(\n",
    "            [TransformerBlock(hidden, attn_heads, hidden * 4, dropout) for _ in range(n_layers)])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Cross_effect embedding\n",
    "        self.alpha_inter_embeddings = torch.nn.Embedding(vocab_size * 2, hidden//2)\n",
    "        self.alpha_skill_embeddings = torch.nn.Embedding(vocab_size, hidden//2)\n",
    "        self.beta_inter_embeddings = torch.nn.Embedding(vocab_size * 2, hidden)\n",
    "        self.beta_skill_embeddings = torch.nn.Embedding(vocab_size, hidden)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.pred = nn.Linear(hidden, 1)\n",
    "        \n",
    "        \n",
    "        self.finalEmbedding = torch.nn.Embedding(vocab_size+1, 1)\n",
    "        \n",
    "        self.finalLinear = nn.Linear(99, 99)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, segment_info, times):\n",
    "               \n",
    "\n",
    "#         # inter is just the same as x, which is student response\n",
    "#         # skills = target_id = segment_label\n",
    "# #         x = x.long()\n",
    "        alpha_src_emb = self.alpha_inter_embeddings(x)  # [bs, seq_len, emb]\n",
    "        alpha_target_emb = self.alpha_skill_embeddings(segment_info)\n",
    "        alphas = torch.matmul(alpha_src_emb, alpha_target_emb.transpose(-2, -1))  # [bs, seq_len, seq_len]\n",
    "        \n",
    "        beta_src_emb = self.beta_inter_embeddings(x)  # [bs, seq_len, emb]\n",
    "        beta_target_emb = self.beta_skill_embeddings(segment_info)\n",
    "        betas = torch.matmul(beta_src_emb, beta_target_emb.transpose(-2, -1))  # [bs, seq_len, seq_len]\n",
    "        betas = torch.clamp(betas + 1, min=0, max=10)\n",
    "#         betas = torch.clamp(betas, min=1e-10, max=10)\n",
    "#         print('torch.isnan(betas)',torch.isnan(betas))\n",
    "        \n",
    "        seq_len = segment_info.shape[1]  # 99\n",
    "#         times = times.unsqueeze(-1)  # Add a new dimension at the end of the tensor\n",
    "#         times = times.expand(-1, -1, seq_len)  # Expand the tensor along the new dimension\n",
    "        \n",
    "        \n",
    "        delta_t = (times[:, :, None] - times[:, None, :]).abs().double()\n",
    "        delta_t = torch.log(delta_t + 1e-10) \n",
    "#         print('torch.isnan(delta_t)',torch.isnan(delta_t))\n",
    "#         delta_t = torch.log(delta_t + 1e-10) / np.log(np.e)\n",
    "#         delta_t = torch.log(delta_t + 1e-10) / np.log(self.time_log) \n",
    "\n",
    "\n",
    "\n",
    "#         betas = betas.unsqueeze(-1)  # Add a new dimension at the end of the tensor\n",
    "        cross_effects = alphas * torch.exp(-betas * delta_t)  # [64,99,99]\n",
    "#         print('torch.isnan(cross_effects)',torch.isnan(cross_effects), 'cross_effects.size()', cross_effects.size())\n",
    "#         seq_len = segment_info.shape[1]  # 99\n",
    "#         valid_mask = np.triu(np.ones((1, seq_len, seq_len)), k=1)\n",
    "        valid_mask = np.triu(np.ones((1, seq_len, seq_len)), k=1)\n",
    "        mask = (torch.from_numpy(valid_mask) == 0)\n",
    "#         mask = mask.cuda() if self.gpu != '' else mask\n",
    "        mask = mask.cuda()\n",
    "#         sum_t = cross_effects.masked_fill(mask, 0)\n",
    "        sum_t = cross_effects.masked_fill(mask, 0).sum(-2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        # attention masking for padded token\n",
    "        # torch.ByteTensor([batch_size, 1, seq_len, seq_len)\n",
    "        mask = (x > 0).unsqueeze(1).repeat(1, x.size(1), 1).unsqueeze(1)\n",
    "        \n",
    "        # embedding the indexed sequence to sequence of vectors\n",
    "        x = self.embedding(x, segment_info)  # [64, 99, 128]\n",
    "        \n",
    "\n",
    "        # running over multiple transformer blocks\n",
    "        for transformer in self.transformer_blocks:\n",
    "            x = transformer.forward(x, mask)  # [64, 99, 128]\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         x = x.squeeze(-1)\n",
    "\n",
    "#         # apply the cross effects to the output of the transformer blocks before passing it through the prediction layer.\n",
    "#         x = x * sum_t\n",
    "        \n",
    "        \n",
    "#         x = x.squeeze(-1).long()\n",
    "#         print('x1',x,'x.size()',x.size())\n",
    "        \n",
    "#         x = self.finalEmbedding(x).squeeze(dim=-1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = self.pred(x)  # [64,99,1]\n",
    "        x = x.squeeze(-1)\n",
    "\n",
    "#         print('x.size(-1)',x.size(-1),'sum_t.size(-1)',sum_t.size(-1))\n",
    "#         fc = nn.Linear(x.size(-1) + sum_t.size(-1), 1)\n",
    "#         print(fc.size())\n",
    "\n",
    "#         x = self.finalLinear((x+sum_t).float())\n",
    "        \n",
    "#         print('x',x,'x.size()',x.size())\n",
    "#         x = fc(x + sum_t)  # [64,99]\n",
    "\n",
    "#         return x.squeeze(-1)\n",
    "        x = x+ sum_t\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbceddf",
   "metadata": {},
   "source": [
    "## Embedding\n",
    "Each type of embedding serves a different purpose in the BERT model.\n",
    "\n",
    "The BERTEmbedding class has four main parts:\n",
    "\n",
    "- The `TokenEmbedding` module, which is a subclass of nn.Embedding that represents each token in the input sequence as a vector of fixed length.\n",
    "\n",
    "- The `PositionalEmbedding` module, which adds position information to the input representation by using sinusoidal functions of the position index.\n",
    "\n",
    "- The `SegmentEmbedding` module, which represents the sentence segment (e.g., \"sentence A\" or \"sentence B\") of each token in the input sequence as a vector of fixed length.\n",
    "\n",
    "- The `Cross_effect` modules, which represent the interactions between different skills and interleavings as vectors of fixed length.\n",
    "\n",
    "Together, these embeddings provide BERT with a rich representation of the input text that it can use to perform various natural language understanding tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "2378b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Embedding):\n",
    "    def __init__(self, vocab_size, embed_size=128):\n",
    "        super().__init__(vocab_size, embed_size, padding_idx=0)\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len=128):\n",
    "#     def __init__(self, d_model, max_len=99):\n",
    "        super().__init__()\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "class SegmentEmbedding(nn.Embedding):\n",
    "#     def __init__(self, embed_size=128):\n",
    "#         super().__init__(3, embed_size, padding_idx=0)\n",
    "    def __init__(self, vocab_size, embed_size=128):\n",
    "        super().__init__(vocab_size, embed_size, padding_idx=0)\n",
    "\n",
    " \n",
    "        \n",
    "        \n",
    "        \n",
    "class BERTEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    BERT Embedding which is consisted with under features\n",
    "        1. TokenEmbedding : normal embedding matrix\n",
    "        2. PositionalEmbedding : adding positional information using sin, cos\n",
    "        2. SegmentEmbedding : adding sentence segment info, (sent_A:1, sent_B:2)\n",
    "        sum of all these features are output of BERTEmbedding\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embed_size, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param vocab_size: total vocab size\n",
    "        :param embed_size: embedding size of token embedding\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "#The self.token.embedding_dim attribute specifies the size of the embedding dimension for the tokens. In other words, it determines the length of the vectors that will be used to represent each token in the input sequence. This is a fixed property of the model and cannot be changed once it has been initialized.\n",
    "#          self.token = TokenEmbedding(vocab_size=vocab_size, embed_size=embed_size)\n",
    "        self.token = TokenEmbedding(vocab_size=2*vocab_size+1, embed_size=embed_size)\n",
    "        self.position = PositionalEmbedding(d_model=self.token.embedding_dim)\n",
    "#         self.position = PositionalEmbedding(max_len=99, d_model=self.token.embedding_dim)\n",
    "\n",
    "# max_len=100 is also ok!!!\n",
    "#         self.position = PositionalEmbedding(max_len=100, d_model=self.token.embedding_dim)\n",
    "        self.segment = SegmentEmbedding(vocab_size=vocab_size+1, embed_size=self.token.embedding_dim)\n",
    "        \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "    def forward(self, sequence, segment_label):\n",
    "        \n",
    "        x = self.token(sequence) + self.position(sequence) + self.segment(segment_label)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "b526c13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13523"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_skill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccebb09",
   "metadata": {},
   "source": [
    "AssertionError: \n",
    "The error message you are seeing indicates that there is an issue with the BERT model that you are trying to instantiate. The specific error is that the d_model argument must be divisible by the h argument, but this is not the case in your code.\n",
    "\n",
    "The d_model and h arguments correspond to the hidden size of the model and the number of attention heads, respectively. In order to fix the error, you need to make sure that the hidden size is divisible by the number of attention heads.\n",
    "```\n",
    "model = BERT(vocab_size=n_skill, hidden=128, attn_heads=4)\n",
    "model = BERT(vocab_size=n_skill, hidden=128*4, attn_heads=4)\n",
    "model = BERT(vocab_size=n_skill, hidden=128, attn_heads=2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "c6ef645d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT(\n",
       "  (embedding): BERTEmbedding(\n",
       "    (token): TokenEmbedding(27047, 128, padding_idx=0)\n",
       "    (position): PositionalEmbedding()\n",
       "    (segment): SegmentEmbedding(13524, 128, padding_idx=0)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_blocks): ModuleList(\n",
       "    (0): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attention): Attention()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFeedForward(\n",
       "        (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (input_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attention): Attention()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFeedForward(\n",
       "        (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (input_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attention): Attention()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFeedForward(\n",
       "        (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (input_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attention): Attention()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFeedForward(\n",
       "        (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (input_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attention): Attention()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFeedForward(\n",
       "        (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (input_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attention): Attention()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFeedForward(\n",
       "        (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (input_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attention): Attention()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFeedForward(\n",
       "        (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (input_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attention): Attention()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFeedForward(\n",
       "        (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (input_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attention): Attention()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFeedForward(\n",
       "        (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (input_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attention): Attention()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFeedForward(\n",
       "        (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (input_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attention): Attention()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFeedForward(\n",
       "        (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (input_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attention): MultiHeadedAttention(\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attention): Attention()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): PositionwiseFeedForward(\n",
       "        (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (input_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output_sublayer): SublayerConnection(\n",
       "        (norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (alpha_inter_embeddings): Embedding(27046, 64)\n",
       "  (alpha_skill_embeddings): Embedding(13523, 64)\n",
       "  (beta_inter_embeddings): Embedding(27046, 128)\n",
       "  (beta_skill_embeddings): Embedding(13523, 128)\n",
       "  (pred): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (finalEmbedding): Embedding(13524, 1)\n",
       "  (finalLinear): Linear(in_features=99, out_features=99, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # chatGPT model \n",
    "# # Create a BERT model with 4 attention heads and a model size of 128\n",
    "\n",
    "# # Define the number of words in the input vocabulary\n",
    "# num_embeddings = 10000\n",
    "\n",
    "# # Define the maximum length of the input sequence\n",
    "# num_positions = 512\n",
    "\n",
    "# # Define the number of token types in the input\n",
    "# # For example, the BERT tokenizer used in the example code uses the \"bert-base-uncased\" pre-trained model, which uses a vocabulary of 30,522 tokens. This means that the BERT model will use 30,522 different token types to represent the input text. However, this is just one example, and the number of token types used by a BERT model can vary depending on the specific pre-trained model and tokenization scheme that is used.\n",
    "# num_token_types = 2\n",
    "\n",
    "\n",
    "# # Create a BERT embedding layer with a model size of 128, a vocabulary size of 10000, and a dropout rate of 0.1\n",
    "# # # Create a position-wise feed-forward network with a model size of 128 and a hidden layer size of 512\n",
    "# model = BERT(4, 128, 512)\n",
    "\n",
    "\n",
    "# Official BERT model\n",
    "model = BERT(vocab_size=n_skill,attn_heads=8)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d8690d",
   "metadata": {},
   "source": [
    "## Define Train process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "28bedd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, dataloader, optimizer, scheduler, criterion, device=\"cpu\"):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = []\n",
    "    num_corrects = 0\n",
    "    num_total = 0\n",
    "    labels = []\n",
    "    outs = []\n",
    "\n",
    "    for item in dataloader:\n",
    "#         x = item[0]\n",
    "#         print('x',x, 'x.size()',x.size())\n",
    "        x = item[0].to(device).long()\n",
    "        segment_info = item[1].to(device).long()\n",
    "        times = item[2].to(device).long()\n",
    "        \n",
    "        label = item[3].to(device).float()\n",
    "        \n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x, segment_info, times)\n",
    "#         print('output',output, 'output.size()',output.size())\n",
    "              \n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "        \n",
    "        target_mask = (segment_info != 0)  # Create a mask indicating which values in segment_info are not 0\n",
    "        last_nonzero_idx = target_mask.sum(dim=1) - 1  # Find the last non-zero value for each batch\n",
    "        \n",
    "        output = output[range(last_nonzero_idx.size()[0]), last_nonzero_idx]  # Index into the output tensor using last_nonzero_idx\n",
    "        label = label[range(last_nonzero_idx.size()[0]), last_nonzero_idx]  # Index into the label tensor using last_nonzero_idx\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('output',output, 'output.size()',output.size())\n",
    "        print('label',label, 'label.size()',label.size())\n",
    "              \n",
    "#         print('output = output[range(64), last_nonzero_idx]', output,'output.size()',output.size())\n",
    "    \n",
    "        pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "        print('pred',pred, 'pred.size()',pred.size())\n",
    "        \n",
    "        \n",
    "        \n",
    "#         output = torch.masked_select(output, target_mask)\n",
    "#         label = torch.masked_select(label, target_mask)\n",
    "#         pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "        \n",
    "#         print('output = torch.masked_select(output, target_mask)', output,'output.size()',output.size())\n",
    "        \n",
    "#         print('label = torch.masked_select(label, target_mask)', label,'label.size()',label.size())\n",
    "#         print('pred = (torch.sigmoid(output) >= 0.5).long()', pred, 'pred.size()',pred.size())\n",
    "        \n",
    "        num_corrects += (pred == label).sum().item()\n",
    "        num_total += len(label)\n",
    "\n",
    "#         labels.extend(label.view(-1).data.cpu().numpy())\n",
    "#         outs.extend(output.view(-1).data.cpu().numpy())\n",
    "        labels.extend(label.data.cpu().numpy())\n",
    "        outs.extend(output.data.cpu().numpy())\n",
    "        \n",
    "    acc = num_corrects / num_total\n",
    "    auc = roc_auc_score(labels, outs)\n",
    "    loss = np.mean(train_loss)\n",
    "\n",
    "    return loss, acc, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e72be72",
   "metadata": {},
   "source": [
    "## Define Test process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d44184f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_fn(model, dataloader, criterion, device=\"cpu\"):\n",
    "    model.eval()\n",
    "\n",
    "    valid_loss = []\n",
    "    num_corrects = 0\n",
    "    num_total = 0\n",
    "    labels = []\n",
    "    outs = []\n",
    "\n",
    "    for item in dataloader:\n",
    "        x = item[0].to(device).long()\n",
    "        segment_info = item[1].to(device).long()\n",
    "        times = item[2].to(device).long()\n",
    "        \n",
    "        label = item[3].to(device).float()\n",
    "#         target_mask = (segment_info != 0)\n",
    "\n",
    "        output= model(x, segment_info)\n",
    "        loss = criterion(output, label)\n",
    "        valid_loss.append(loss.item())\n",
    "\n",
    "        \n",
    "        \n",
    "        target_mask = (segment_info != 0)  # Create a mask indicating which values in segment_info are not 0\n",
    "        \n",
    "        last_nonzero_idx = target_mask.sum(dim=1) - 1  # Find the last non-zero value for each batch\n",
    "        \n",
    "        output = output[range(last_nonzero_idx.size()[0]), last_nonzero_idx]  # Index into the output tensor using last_nonzero_idx\n",
    "        label = label[range(last_nonzero_idx.size()[0]), last_nonzero_idx]  # Index into the label tensor using last_nonzero_idx\n",
    "\n",
    "#         output = torch.masked_select(output, target_mask)\n",
    "#         label = torch.masked_select(label, target_mask)\n",
    "        pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "#         pred = (torch.sigmoid(output) >= 0.5)\n",
    "    \n",
    "        num_corrects += (pred == label).sum().item()\n",
    "        num_total += len(label)\n",
    "\n",
    "        labels.extend(label.view(-1).data.cpu().numpy())\n",
    "        outs.extend(output.view(-1).data.cpu().numpy())\n",
    "\n",
    "    acc = num_corrects / num_total\n",
    "    auc = roc_auc_score(labels, outs)\n",
    "    loss = np.mean(valid_loss)\n",
    "\n",
    "    return loss, acc, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb870691",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dda76c",
   "metadata": {},
   "source": [
    "- **Criterion**: BCELoss and BCEWithLogitsLoss are both functions used to calculate the binary cross-entropy loss for a given set of predicted and target values. The main difference between the two is that BCEWithLogitsLoss applies a sigmoid function to the predicted values, whereas BCELoss expects the predicted values to already be in the range of 0 to 1. The negative log likelihood loss (which BERT use originally), also known as the cross-entropy loss, is a common loss function used in classification tasks, particularly when working with a multi-class classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "824c11a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output tensor([ -5.2062e+01,  -6.9609e+00,   2.6880e+01,  -4.5676e+01,  -8.2700e+01,\n",
      "          1.4646e+01,   1.2234e+02,  -2.5002e+01,  -5.3937e+01,  -5.1212e+01,\n",
      "         -1.2794e+02,   6.7122e+01,   1.7777e+02, -2.2531e+100,  -6.5031e+01,\n",
      "          9.7545e+01,  -6.9896e+99,   8.1997e+36,  -3.6284e+01,   2.4067e+02,\n",
      "         -1.2594e+02,   1.6713e+02,  -4.2773e+01,  -1.8873e+00,   8.8455e+00,\n",
      "          5.0615e+00,  -1.2903e+01,   1.3374e+02,  -4.1311e+72,   7.3560e+01,\n",
      "          3.1650e+01,  -2.6523e+01,   1.7860e+02,  -2.4671e+01,   1.7900e+14,\n",
      "          7.7845e+01,   4.6255e+91,   1.9556e+01,  -6.9970e+01,  -8.2393e+00,\n",
      "         -6.1273e+01,   2.8261e+02,   3.4242e+01,   7.6701e+01,   8.4990e+01,\n",
      "          1.7608e+01,   1.2970e+02,  -2.3921e+02,   7.8888e+01,   1.1543e+02,\n",
      "          4.4623e+01,   2.3862e+02,   3.5455e+01,  -1.9240e+01,  -7.9682e+01,\n",
      "          9.1805e+01,  -8.9153e+01,  -5.5195e+01,  -4.2838e+01,   1.1818e+01,\n",
      "          1.7123e+02,   9.9363e+01,   1.7691e+02,   1.6078e+01],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 0., 0., 1.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([-2.3067e+00,         nan,         nan,  5.6670e+01,  1.1394e+02,\n",
      "                nan,  4.5672e+01,         nan, 8.3375e+100,         nan,\n",
      "                nan,  4.5265e+01,         nan,  8.7732e+00,         nan,\n",
      "                nan,         nan,         nan,         nan,  9.5324e+01,\n",
      "                nan,         nan,         nan,         nan, -6.0845e+01,\n",
      "                nan,         nan,         nan,         nan,  7.4422e+00,\n",
      "                nan,         nan, 5.7209e+100,  3.6430e+01,         nan,\n",
      "                nan,         nan,         nan,         nan,         nan,\n",
      "                nan,  1.5881e+01, -1.0763e+02,         nan,  7.8598e+01,\n",
      "                nan,         nan, -4.9259e+01,         nan,         nan,\n",
      "                nan,         nan,  2.8545e+00,         nan,         nan,\n",
      "                nan,         nan,  2.8281e+01,         nan,         nan,\n",
      "                nan,         nan, -8.4992e+00,         nan], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 1., 0., 0., 1., 0.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 1., 0., 1.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 1.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 0., 1., 1., 0., 1.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 1., 1., 1.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 0., 1., 1.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 0., 1., 0.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 0., 0., 1., 0.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 1.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 0., 1., 1.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 1., 0., 0., 1., 0.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 1., 0., 0.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 1., 1., 1., 1., 0.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 1., 0., 0.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 1., 1., 0., 1.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 1., 0., 0., 1.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 0., 0., 0.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 1., 0., 1.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
      "        1., 0., 1., 0., 0., 1., 0., 1., 0., 0.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 0., 0., 1.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 0., 0., 1.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 1., 0., 1.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 0., 1., 0.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 0., 1.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 0., 0., 0.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 0., 0., 0., 1.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 1., 0., 0.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 1., 0., 1., 1., 0., 0.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 1., 0., 0.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 0., 0., 0.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n",
      "output tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<IndexBackward0>) output.size() torch.Size([64])\n",
      "label tensor([0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 1., 1.], device='cuda:0') label.size() torch.Size([64])\n",
      "pred tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') pred.size() torch.Size([64])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [274]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m---> 19\u001b[0m     loss, acc, auc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch - \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m train: loss-\u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m, acc-\u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m, auc - \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, EPOCHS, loss, acc, auc))\n\u001b[1;32m     21\u001b[0m     loss, acc, auc \u001b[38;5;241m=\u001b[39m valid_fn(model, valid_dataloader, criterion, device)\n",
      "Input \u001b[0;32mIn [272]\u001b[0m, in \u001b[0;36mtrain_fn\u001b[0;34m(model, dataloader, optimizer, scheduler, criterion, device)\u001b[0m\n\u001b[1;32m     15\u001b[0m         times \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m     17\u001b[0m         label \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 21\u001b[0m         \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(x, segment_info, times)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#         print('output',output, 'output.size()',output.size())\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py:249\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    247\u001b[0m     p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m foreach \u001b[38;5;129;01mor\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mis_sparse):\n\u001b[0;32m--> 249\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     per_device_and_dtype_grads[p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdevice][p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdtype]\u001b[38;5;241m.\u001b[39mappend(p\u001b[38;5;241m.\u001b[39mgrad)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# try using SGD with weight decay\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion = nn.BCELoss()\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=MAX_LEARNING_RATE, steps_per_epoch=len(train_dataloader), epochs=EPOCHS)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "\n",
    "best_auc = 0\n",
    "max_steps = 3\n",
    "step = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    loss, acc, auc = train_fn(model, train_dataloader, optimizer, scheduler, criterion, device)\n",
    "    print(\"epoch - {}/{} train: loss-{:.4f}, acc-{:.4f}, auc - {:.4f}\".format(epoch+1, EPOCHS, loss, acc, auc))\n",
    "    loss, acc, auc = valid_fn(model, valid_dataloader, criterion, device)\n",
    "    print(\"epoch - {}/{} valid: loss-{:.4f}, [acc-{:.4f}, auc - {:.4f}]\".format(epoch+1, EPOCHS, loss, acc, auc))\n",
    "\n",
    "    \n",
    "    if auc > best_auc:\n",
    "        best_auc = auc\n",
    "        step = 0\n",
    "        torch.save(model.state_dict(), \"bert_cross_model.pt\")\n",
    "    else:\n",
    "        step += 1\n",
    "        if step >= max_steps:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc2bf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.8087"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652ff967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfeff59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298c423a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac3cc8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d34b93d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5250883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee7bb95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22882266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfa6a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90b3429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2f76af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
